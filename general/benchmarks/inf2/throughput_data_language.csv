Model,Scripts,Framework,Inst. Type,Task,Throughput (inference/second),Latency P50 (ms),Latency P99 (ms),Application Type,Neuron Version,Run Mode,Batch Size,Sequence Length,Model Data Type,Compilation Autocast Data Type,OS Type
albert-base-v2,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),2918.53,10.79,13.51,Batch,2.11.0,Data Parallel,16,128,FP32,Matmult-BF16,AL2
bert-base-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),2842.53,5.52,6.92,Batch,2.11.0,Data Parallel,8,128,FP32,Matmult-BF16,AL2
bert-base-cased-finetuned-mrpc,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Sequence Classification,3155.32,4.84,5.71,Batch,2.11.0,Data Parallel,8,128,FP32,Matmult-BF16,AL2
bert-base-uncased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),2825.07,11,13.12,Batch,2.11.0,Data Parallel,16,128,FP32,Matmult-BF16,AL2
bert-large-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),786.31,19.88,25.16,Batch,2.11.0,Data Parallel,8,128,FP32,Matmult-BF16,AL2
bert-large-uncased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),812.15,38.85,50.37,Batch,2.11.0,Data Parallel,16,128,FP32,Matmult-BF16,AL2
camembert-base,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),2854.86,11.1,11.8,Batch,2.11.0,Data Parallel,16,128,FP32,Matmult-BF16,AL2
distilbert-base-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),5109.2,18.42,20.6,Batch,2.11.0,Data Parallel,48,128,FP32,Matmult-BF16,AL2
distilbert-base-uncased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),5071.05,18.5,21.97,Batch,2.11.0,Data Parallel,48,128,FP32,Matmult-BF16,AL2
google/electra-base-discriminator,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),2889.27,5.45,6.26,Batch,2.11.0,Data Parallel,8,128,FP32,Matmult-BF16,AL2
gpt2,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),2642.09,12.05,13.02,Batch,2.11.0,Data Parallel,16,128,FP32,Matmult-BF16,AL2
gpt2-medium,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),920.14,16.78,20.94,Batch,2.11.0,Data Parallel,8,128,FP32,Matmult-BF16,AL2
roberta-base,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),2855.99,5.56,5.98,Batch,2.11.0,Data Parallel,8,128,FP32,Matmult-BF16,AL2
roberta-large,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),971.97,16.14,19.08,Batch,2.11.0,Data Parallel,8,128,FP32,Matmult-BF16,AL2
gpt2-large,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.48xlarge,Raw Output (AutoModel),440.78,17.58,21.39,Batch,2.11.0,Data Parallel,4,128,FP32,Matmult-BF16,AL2
xlm-roberta-base,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.48xlarge,Raw Output (AutoModel),30.25,66.06,72.74,Batch,2.11.0,Data Parallel,1,128,FP32,Matmult-BF16,AL2
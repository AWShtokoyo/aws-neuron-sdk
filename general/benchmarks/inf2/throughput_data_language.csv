Model,Scripts,Framework,Inst. Type,Task,Throughput (inference/second),Latency P50 (ms),Latency P99 (ms),Application Type,Neuron Version,Run Mode,Batch Size,Sequence Length,Model Data Type,Compilation Autocast Data Type,OS Type
albert-base-v2,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),3025.78,10.52,10.9,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22
bert-base-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),2822.93,11.08,13.57,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22
bert-base-cased-finetuned-mrpc,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Sequence Classification,3318.35,9.47,11.87,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22
bert-base-uncased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),2862.04,10.96,12.65,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22
bert-large-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),847.40,9.2,12.05,Batch,2.14.0,Data Parallel,4,128,FP32,Matmult-BF16,U22
bert-large-uncased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),849.77,18.64,23.8,Batch,2.14.0,Data Parallel,8,128,FP32,Matmult-BF16,U22
camembert-base,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),2901.54,10.96,11.43,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22
distilbert-base-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),5224.70,6.03,6.61,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22
distilbert-base-cased-distilled-squad,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),5299.93,5.97,6.55,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22
distilbert-base-uncased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),5254.63,6.01,6.6,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22
google/electra-base-discriminator,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),2945.94,10.66,11.72,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22
gpt2,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),3094.11,10.18,11.13,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22
gpt2-medium,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),1009.97,15.13,19.09,Batch,2.14.0,Data Parallel,8,128,FP32,Matmult-BF16,U22
roberta-base,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),2885.51,11,11.6,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22
roberta-large,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),965.33,16.10,19.26,Batch,2.14.0,Data Parallel,8,128,FP32,Matmult-BF16,U22
gpt2-large,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.48xlarge,Raw Output (AutoModel),402.67,40.1,45.93,Batch,2.14.0,Data Parallel,8,128,FP32,Matmult-BF16,U22
xlm-roberta-base,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.48xlarge,Raw Output (AutoModel),48.66,649.81,820.93,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22

Model,Scripts,Framework,Inst. Type,Task,Throughput (inference/second),Latency P50 (ms),Latency P99 (ms),Application Type,Neuron Version,Run Mode,Batch Size,Sequence Length,Model Data Type,Compilation Autocast Data Type,OS Type
albert-base-v2,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),2054.54,0.96,1.05,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
bert-base-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),1854.05,1.08,1.13,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
bert-base-cased-finetuned-mrpc,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Sequence Classification,2042.32,0.97,1.03,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
bert-base-uncased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),1857.69,1.08,1.12,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
bert-large-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),685.83,2.87,3.34,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
bert-large-uncased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),681.99,2.85,3.48,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
camembert-base,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),1939.97,1.02,1.1,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
distilbert-base-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),3081.57,0.65,0.68,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
distilbert-base-cased-distilled-squad,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),3082.88,0.65,0.69,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
distilbert-base-uncased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),3087.43,0.65,0.69,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
google/electra-base-discriminator,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),1963.85,1.01,1.07,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
gpt2,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),1963.05,1.01,1.07,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
gpt2-medium,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),743.8,2.68,2.76,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
roberta-base,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),1956.66,1.01,1.09,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
roberta-large,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.xlarge,Raw Output (AutoModel),721.2,2.77,2.86,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
gpt2-large,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.48xlarge,Raw Output (AutoModel),310.51,6.18,7.35,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
xlm-roberta-base,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,Inf2.48xlarge,Raw Output (AutoModel),40.05,49.87,61.21,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
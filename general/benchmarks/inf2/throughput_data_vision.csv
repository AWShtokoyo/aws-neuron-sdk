Model,Image Size,Scripts,Framework,Inst. Type,Task,Throughput (inference/sec),Latency P50 (ms),Latency P99 (ms),Application Type,Neuron Version,Run Mode,Batch Size,Model Data Type,Compilation Autocast Data Type
google/vit-base-patch16-224,224x224,:benchmark-pt:`Benchmark <hf-google-vit>`,PyTorch 1.13.1,Inf2.xlarge,Image Classification,1318.418,96.317,112.46,Batch,2.11.0,Data Parallel,32,FP32,Matmult-BF16
resnet18,224x224,:benchmark-pt:`Benchmark <resnet>`,PyTorch 1.13.1,Inf2.xlarge,Image Classification,5792.49,5.52,5.568,Batch,2.11.0,Data Parallel,8,FP32,Matmult-BF16
resnet34,224x224,:benchmark-pt:`Benchmark <resnet>`,PyTorch 1.13.1,Inf2.xlarge,Image Classification,4497.893,7.102,7.159,Batch,2.11.0,Data Parallel,8,FP32,Matmult-BF16
resnet50,224x224,:benchmark-pt:`Benchmark <resnet>`,PyTorch 1.13.1,Inf2.xlarge,Image Classification,3878.525,8.241,8.301,Batch,2.11.0,Data Parallel,8,FP32,Matmult-BF16
resnet101,224x224,:benchmark-pt:`Benchmark <resnet>`,PyTorch 1.13.1,Inf2.xlarge,Image Classification,3042.733,84.038,84.179,Batch,2.11.0,Data Parallel,64,FP32,Matmult-BF16
resnet152,224x224,:benchmark-pt:`Benchmark <resnet>`,PyTorch 1.13.1,Inf2.xlarge,Image Classification,2301.624,111.076,111.264,Batch,2.11.0,Data Parallel,64,FP32,Matmult-BF16
Stable Diffusion 2.1,512x512,:benchmark-pt:`Benchmark <sd2_512>`,PyTorch 1.13.1,Inf2.xlarge,Image Generation,0.47,2127,2313,Real Time,2.11.0,Data Parallel,1,FP32,Matmult-BF16
Stable Diffusion 2.1,768x768,:benchmark-pt:`Benchmark <sd2_768>`,PyTorch 1.13.1,Inf2.xlarge,Image Generation,0.144,6960,7632,Real Time,2.11.0,Data Parallel,1,FP32,Matmult-BF16
UNet,224x224,:benchmark-pt:`Benchmark <unet>`,PyTorch 1.13.1,Inf2.xlarge,Image Segmentation,810.287,19.743,19.945,Batch,2.11.0,Data Parallel,4,FP32,Matmult-BF16
vgg11,224x224,:benchmark-pt:`Benchmark <vgg>`,PyTorch 1.13.1,Inf2.xlarge,Image Classification,3404.467,74.809,75.294,Batch,2.11.0,Data Parallel,64,FP32,Matmult-BF16
vgg16,224x224,:benchmark-pt:`Benchmark <vgg>`,PyTorch 1.13.1,Inf2.xlarge,Image Classification,1782.525,17.943,18.068,Batch,2.11.0,Data Parallel,8,FP32,Matmult-BF16

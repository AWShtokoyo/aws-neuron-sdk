Model,Scripts,Framework,Inst. Type,Task,Throughput (inference/sec),Latency P50 (ms),Latency P99 (ms),Application Type,Neuron Version,Run Mode,Batch Size,Sequence Length,Model Data Type,Compilation Autocast Data Type,OS Type
albert-base-v2,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),3070,10.39,10.60,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22
bert-base-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),3034.26,10.51,10.62,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22
bert-base-cased-finetuned-mrpc,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Sequence Classification,3435.5,9.31,9.33,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22
bert-base-uncased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),2919.54,5.48,5.51,Batch,2.14.0,Data Parallel,8,128,FP32,Matmult-BF16,U22
bert-large-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),994.75,8.05,8.07,Batch,2.14.0,Data Parallel,4,128,FP32,Matmult-BF16,U22
bert-large-uncased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),1033.36,15.48,15.55,Batch,2.14.0,Data Parallel,8,128,FP32,Matmult-BF16,U22
camembert-base,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),2943.2,10.85,11.06,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22
distilbert-base-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),5380.35,5.94,6,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22
distilbert-base-cased-distilled-squad,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),5373.35,6,5.94,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22
distilbert-base-uncased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),5350.07,5.98,6.02,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22
google/electra-base-discriminator,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),3039.13,10.51,10.62,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22
gpt2,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),3181.2,10.05,10.11,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22
gpt2-medium,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),1104.12,28.96,29.09,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22
roberta-base,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),2917.64,10.96,11.05,Batch,2.14.0,Data Parallel,16,128,FP32,Matmult-BF16,U22
roberta-large,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),1021.49,15.65,15.72,Batch,2.14.0,Data Parallel,8,128,FP32,Matmult-BF16,U22
gpt2-large,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.32xlarge,Raw Output (AutoModel),530.34,30.16,30.21,Batch,2.14.0,Data Parallel,8,128,FP32,Matmult-BF16,U22
xlm-roberta-base,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.32xlarge,Raw Output (AutoModel),46.52,344.02,346.33,Batch,2.14.0,Data Parallel,4,128,FP32,Matmult-BF16,U22

Model,Scripts,Framework,Inst. Type,Task,Throughput (inference/sec),Latency P50 (ms),Latency P99 (ms),Application Type,Neuron Version,Run Mode,Batch Size,Sequence Length,Model Data Type,Compilation Autocast Data Type,OS Type
albert-base-v2,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),1988.87,0.98,1.07,Real Time,2.11.0,Data Parallel,1,128,FP32,Matmult-BF16,AL2
bert-base-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),1913.94,1.04,1.09,Real Time,2.11.0,Data Parallel,1,128,FP32,Matmult-BF16,AL2
bert-base-cased-finetuned-mrpc,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Sequence Classification,2056.23,0.97,0.99,Real Time,2.11.0,Data Parallel,1,128,FP32,Matmult-BF16,AL2
bert-base-uncased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),1922.1,1.03,1.09,Real Time,2.11.0,Data Parallel,1,128,FP32,Matmult-BF16,AL2
bert-large-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),708.86,2.82,2.86,Real Time,2.11.0,Data Parallel,1,128,FP32,Matmult-BF16,AL2
bert-large-uncased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),710.68,2.81,2.86,Real Time,2.11.0,Data Parallel,1,128,FP32,Matmult-BF16,AL2
camembert-base,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),1831.08,1.09,1.13,Real Time,2.11.0,Data Parallel,1,128,FP32,Matmult-BF16,AL2
distilbert-base-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),3175.87,0.63,0.66,Real Time,2.11.0,Data Parallel,1,128,FP32,Matmult-BF16,AL2
distilbert-base-uncased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),3171.3,0.63,0.67,Real Time,2.11.0,Data Parallel,1,128,FP32,Matmult-BF16,AL2
google/electra-base-discriminator,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),1944.28,1.02,1.07,Real Time,2.11.0,Data Parallel,1,128,FP32,Matmult-BF16,AL2
gpt2,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),1660.21,1.19,1.24,Real Time,2.11.0,Data Parallel,1,128,FP32,Matmult-BF16,AL2
gpt2-medium,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),634.46,3.1,3.22,Real Time,2.11.0,Data Parallel,1,128,FP32,Matmult-BF16,AL2
roberta-base,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),1835.41,1.09,1.12,Real Time,2.11.0,Data Parallel,1,128,FP32,Matmult-BF16,AL2
roberta-large,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),712.57,2.81,2.86,Real Time,2.11.0,Data Parallel,1,128,FP32,Matmult-BF16,AL2
gpt2-large,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.32xlarge,Raw Output (AutoModel),282.46,7.01,7.13,Real Time,2.11.0,Data Parallel,1,128,FP32,Matmult-BF16,AL2
xlm-roberta-base,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.32xlarge,Raw Output (AutoModel),29,67.78,77.44,Real Time,2.11.0,Data Parallel,1,128,FP32,Matmult-BF16,AL2
Model,Scripts,Framework,Inst. Type,Task,Throughput (inference/sec),Latency P50 (ms),Latency P99 (ms),Application Type,Neuron Version,Run Mode,Batch Size,Sequence Length,Model Data Type,Compilation Autocast Data Type,OS Type
albert-base-v2,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),2032.6,0.98,1.01,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
bert-base-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),1913.59,1.04,1.08,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
bert-base-cased-finetuned-mrpc,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Sequence Classification,2054.97,0.98,0.99,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
bert-base-uncased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),1913.41,1.04,1.08,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
bert-large-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),731.01,2.73,2.77,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
bert-large-uncased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),731.11,2.74,2.77,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
camembert-base,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),1927.71,1.04,1.06,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
distilbert-base-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),3186.27,0.62,0.65,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
distilbert-base-cased-distilled-squad,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),3184.77,0.63,0.65,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
distilbert-base-uncased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),3179.04,0.63,0.65,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
google/electra-base-discriminator,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),1977.9,1.01,1.05,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
gpt2,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),2038.77,0.97,1.03,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
gpt2-medium,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),749.56,2.66,2.71,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
roberta-base,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),1929.94,1.04,1.06,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
roberta-large,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.2xlarge,Raw Output (AutoModel),720.78,2.78,2.82,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
gpt2-large,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.32xlarge,Raw Output (AutoModel),326.55,6.11,6.17,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
xlm-roberta-base,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.1,trn1.32xlarge,Raw Output (AutoModel),38.5,51.91,52.81,Real Time,2.13.0,Data Parallel,1,128,FP32,Matmult-BF16,U22
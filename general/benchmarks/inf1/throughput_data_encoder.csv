Model,Scripts,Source,Framework,Inst. Type,Num Cores,Seq. Length,Avg Throughput (/sec),Max Throughput,Threads,Latency P50 (ms),Latency P90 (ms),Latency P95 (ms),Latency P99 (ms),Application Type,Neuron Version,Run Mode,Batch Size,N Models,Workers per Model,Model details
BERT base (bert-base-cased),:compile-pt:`Compile <bert-base-cased>` + :benchmark-pt:`Benchmark <bert-base-cased>`,HuggingFace,PyTorch 1.13.1,inf1.xlarge,4,128,1129,,8,55.7,,,61.7,Batch,2.17.0,Data Parallel,8,4,2,"fp32, sequence-length=128"
BERT base (bert-base-uncased),:compile-pt:`Compile <bert-base-uncased>` + :benchmark-pt:`Benchmark <bert-base-uncased>`,HuggingFace,PyTorch 1.13.1,inf1.xlarge,4,128,1181.1,,8,40.6,,,45.4,Batch,2.17.0,Data Parallel,6,4,2,"fp32, sequence-length=128"
DistilBERT base (distilbert-base-uncased-finetuned-sst-2-english),:compile-pt:`Compile <distilbert-base-uncased-finetuned-sst-2-english>` + :benchmark-pt:`Benchmark <distilbert-base-uncased-finetuned-sst-2-english>`,HuggingFace,PyTorch 1.13.1,inf1.xlarge,4,128,1790.7,,8,28.4,,,70.6,Batch,2.17.0,Data Parallel,7,4,2,"fp32, sequence-length=128"
DistilBERT base (distilbert-base-uncased),:compile-pt:`Compile <distilbert-base-uncased>` + :benchmark-pt:`Benchmark <distilbert-base-uncased>`,HuggingFace,PyTorch 1.13.1,inf1.xlarge,4,128,1876.4,,8,33.7,,,53.4,Batch,2.17.0,Data Parallel,8,4,2,"fp32, sequence-length=128"
DistilRoBERTa base (distilroberta-base),:compile-pt:`Compile <distilroberta-base>` + :benchmark-pt:`Benchmark <distilroberta-base>`,HuggingFace,PyTorch 1.13.1,inf1.xlarge,4,128,1527.5,,8,14.9,,,25.8,Batch,2.17.0,Data Parallel,6,4,1,"fp32, sequence-length=128"
BERT base,:ref:`HuggingFace Pretrained BERT </src/examples/pytorch/bert_tutorial/tutorial_pretrained_bert.ipynb>`,,PyTorch 1.13,inf1.xlarge,,,966,,,21,,,21,Batch,2.17.0,Data Parallel,4,,,"fp32, bert-base-cased-finetuned-mrpc, sequence-length=128"
BERT base,:ref:`Using NeuronCore Pipeline </src/examples/pytorch/pipeline_tutorial/neuroncore_pipeline_pytorch.ipynb>`,,PyTorch 1.13,inf1.6xlarge,,,1993.7,,,5.9,,,6.3,Real Time,2.17.0,Model Pipeline,1,,,"fp32, bert-base-uncased, sequence-length=128"
BERT base,:ref:`HuggingFace distilBERT with Tensorflow2 </src/examples/tensorflow/huggingface_bert/huggingface_bert.ipynb>`,,Tensorflow 2.10,inf1.6xlarge,,,2128.3,,,29.9,,,32.2,Batch,2.17.0,Data Parallel,16,,,"fp32, distilbert-base-uncased-finetuned-sst-2-english, sequence-length=128"

Model,Scripts,Source,Framework,Inst. Type,Num Cores,Seq. Length,Avg Throughput (/sec),Max Throughput,Threads,Latency P50 (ms),Latency P90 (ms),Latency P95 (ms),Latency P99 (ms),Application Type,Neuron Version,Run Mode,Batch Size,N Models,Workers per Model,Model details
BERT base (bert-base-cased),:compile-pt:`Compile <bert-base-cased>` + :benchmark-pt:`Benchmark <bert-base-cased>`,HuggingFace,PyTorch 1.13.1,inf1.xlarge,4,128,1119,,8,56.9,,,56.3,Batch,2.16.0,Data Parallel,8,4,2,"fp32, sequence-length=128"
BERT base (bert-base-uncased),:compile-pt:`Compile <bert-base-uncased>` + :benchmark-pt:`Benchmark <bert-base-uncased>`,HuggingFace,PyTorch 1.13.1,inf1.xlarge,4,128,1180.2,,8,10.5,,,10.7,Batch,2.16.0,Data Parallel,6,4,2,"fp32, sequence-length=128"
DistilBERT base (distilbert-base-uncased-finetuned-sst-2-english),:compile-pt:`Compile <distilbert-base-uncased-finetuned-sst-2-english>` + :benchmark-pt:`Benchmark <distilbert-base-uncased-finetuned-sst-2-english>`,HuggingFace,PyTorch 1.13.1,inf1.xlarge,4,128,1880.1,,8,28.6,,,58.4,Batch,2.16.0,Data Parallel,7,4,2,"fp32, sequence-length=128"
DistilBERT base (distilbert-base-uncased),:compile-pt:`Compile <distilbert-base-uncased>` + :benchmark-pt:`Benchmark <distilbert-base-uncased>`,HuggingFace,PyTorch 1.13.1,inf1.xlarge,4,128,1880,,8,28.6,,,60.4,Batch,2.16.0,Data Parallel,8,4,2,"fp32, sequence-length=128"
DistilRoBERTa base (distilroberta-base),:compile-pt:`Compile <distilroberta-base>` + :benchmark-pt:`Benchmark <distilroberta-base>`,HuggingFace,PyTorch 1.13.1,inf1.xlarge,4,128,1521.27,,8,33,,,62.5,Batch,2.16.0,Data Parallel,6,4,1,"fp32, sequence-length=128"
BERT base,:ref:`HuggingFace Pretrained BERT </src/examples/pytorch/bert_tutorial/tutorial_pretrained_bert.ipynb>`,,PyTorch 1.13,inf1.xlarge,,,966,,,21,,,22,Batch,2.16.0,Data Parallel,4,,,"fp32, bert-base-cased-finetuned-mrpc, sequence-length=128"
BERT base,:ref:`Using NeuronCore Pipeline </src/examples/pytorch/pipeline_tutorial/neuroncore_pipeline_pytorch.ipynb>`,,PyTorch 1.13,inf1.6xlarge,,,1993.8,,,6,,,6.3,Real Time,2.16.0,Model Pipeline,1,,,"fp32, bert-base-uncased, sequence-length=128"
BERT base,:ref:`HuggingFace distilBERT with Tensorflow2 </src/examples/tensorflow/huggingface_bert/huggingface_bert.ipynb>`,,Tensorflow 2.10,inf1.6xlarge,,,2092.1,,,30.1,,,33,Batch,2.16.0,Data Parallel,16,,,"fp32, distilbert-base-uncased-finetuned-sst-2-english, sequence-length=128"